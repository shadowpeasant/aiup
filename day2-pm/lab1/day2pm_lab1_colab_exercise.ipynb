{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nyp-sit/aiup/blob/main/day2-pm/lab1/day2pm_lab1_colab_exercise.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IkjYbDqkU8oD"
      },
      "source": [
        "<img src=\"https://www.nyp.edu.sg/content/dam/nyp/logo.png\" width='200'/>\n",
        "\n",
        "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
        "\n",
        "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
        "\n",
        "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or ```Ctrl-Enter``` (run and stay in the current cell).\n",
        "\n",
        "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_2jIVkz_ciq"
      },
      "source": [
        "# Lab 1 - Sentiment Analysis with Scikit-Learn\n",
        "\n",
        "In this lab exercise, we will learn how to perform Sentiment Analysis with Scikit-Learn, a popular Machine Learning toolkit for Classical Machine Learning. Sentiment Analysis is a Text Classification task where you model learns how to classify a paragraph or a document of text into whether it is a positive or a negative sentiment.\n",
        "\n",
        "We will explore using TF-IDF and various Classical Machine Learning algorithms such as Naive Bayes and SVM to classify whether sentiments of movie reviews are positive or negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "URDv6NK1_J0N"
      },
      "outputs": [],
      "source": [
        "!wget https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/aiup/day2-pm/lab1/lab1.zip\n",
        "!unzip lab1.zip\n",
        "\n",
        "from helpers import *\n",
        "print (\"Importing helpers complete.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCu3FO7JU8oH"
      },
      "source": [
        "## Section 1.1 - Explore Your Data\n",
        "\n",
        "Take a look at the IMDB Dataset.csv to see format of the text file that we will be using for this exercise. If you intend to use this set of Jupyter Notebooks later for your own Sentiment Analysis projects, please ensure that you collect your data in this format.\n",
        "\n",
        "There are 50,000 rows in the IMDB Dataset.csv file. We used Excel to cut out 40,000 rows and saved them into the train.csv file, and the remaining 10,000 rows, into the test.csv file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIgSk8KjA2sN"
      },
      "source": [
        "## Section 1.2 - Load Data from CSV\n",
        "\n",
        "Update the following code to load the training and test data from the correct CSV file path, and indicate the appropriate column names to extract the input text, and output classification label.\n",
        "\n",
        "The path to the training file should be **\"data/train.csv\"**, and the path to the test file should be **\"test.csv\"**. The column names to the input text and output labels can be found in the train.csv and test.csv files.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAqxtMB4A2A0"
      },
      "outputs": [],
      "source": [
        "# TODO: Set the filename to the path containing our training and test files. \n",
        "#\n",
        "load_text_data_from_csv_for_scikit(\n",
        "    \"???\",                           # The training CSV file\n",
        "    \"???\",                           # The test CSV file\n",
        "    \"???\",                           # The column in the CSV used as the input text\n",
        "    \"???\")                           # The column in the CSV used as the output classification label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L5m0pS7DU8oK"
      },
      "source": [
        "## Section 1.3 - Display Loaded Data\n",
        "\n",
        "Run the following code to display the training data that we have loaded.\n",
        "\n",
        "Can you identify which parts are the input texts, and which parts are the output labels?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ko5a5Gi6U8oL"
      },
      "outputs": [],
      "source": [
        "display_trainx_trainy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LMyYYay_J0T"
      },
      "source": [
        "## Section 1.4 - Create the Classical Machine Learning Text Classification Model\n",
        "\n",
        "The following creates the Classical Machine Learning model for our Text Classification task. \n",
        "\n",
        "We have written codes for you to create a model with Naive Bayes, or SVM. Let's start with Naive Bayes first.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t-OmcZTG_J0T"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Run either this or SVM.\n",
        "#\n",
        "create_text_classifier_model_naivebayes(\n",
        "    1.0,        # Additive (Laplace/Lidstone) smoothing parameter (0 for no smoothing).\n",
        "    True,       # Whether to learn class prior probabilities or not. If false, a uniform prior will be used.\n",
        "    None        # Prior probabilities of the classes. If specified the priors are not adjusted according to the data.\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEXFsxLrU8oP"
      },
      "outputs": [],
      "source": [
        "# TODO:\n",
        "# Run either this or Naive Bayes.\n",
        "#\n",
        "create_text_classifier_model_svm()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ii0NXEe2_J0Y"
      },
      "source": [
        "## Section 1.5 - Training and Evaluating the Model\n",
        "\n",
        "Run the following cell to perform the training. The data pipeline set up in Scikit-Learn in the helpers already uses NLTK to tokenize (split into words) and lemmatize (convert words into root forms) before converting it into Bag-of-Words + TF-IDF counts and then passing that count into the Machine Learning model. \n",
        "\n",
        "This is how the processing pipeline for Natural Language Processing in Scikit-Learn will look like.\n",
        "\n",
        "<img src=\"https://nyp-aicourse.s3-ap-southeast-1.amazonaws.com/resources/day2-pm/scikit.PNG\" />\n",
        "\n",
        "Once the training is complete, review the results below and look at how well your model is fairing. Take a look at the test data's F1 score, because it is a meaningful metric that tells us how well our model works for data that doesn't exist in the training set.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTaoxoA__J0Y"
      },
      "outputs": [],
      "source": [
        "train_text_classifier_model()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HB0Xdglg_J0b"
      },
      "source": [
        "## Section 1.6 - Saving the Model\n",
        "\n",
        "Let's save the model into a file that we can reload and use later on.\n",
        "\n",
        "Once you have run the following cell, take a look at the file in the folder. \n",
        "\n",
        "If you trained using Naive Bayes, we recommend that you save into a file name such as **\"models/naivebayes.scikit\"**. If you trained your model with SVM, save into a file name such as **\"models/svm.scikit\"**.\n",
        "\n",
        "Once you have saved the model, head back to Step 1.4 to try and train your text classification task with another Machine Learning model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXqlxZku_J0c"
      },
      "outputs": [],
      "source": [
        "# TODO: \n",
        "# Give the model a file name.\n",
        "#\n",
        "save_text_classifier_model(\"???\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiQAH903_J0f"
      },
      "source": [
        "## Section 1.7 - Loading the Model \n",
        "\n",
        "Update the following cell to provide the file name of your model and run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pKYWAzsI_J0f"
      },
      "outputs": [],
      "source": [
        "# TODO: \n",
        "# Update the file name of the model that you want to load.\n",
        "#\n",
        "load_text_classifier_model(\"???\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztWY-2Cq_J0h"
      },
      "source": [
        "## Section 1.8 - Testing the Model\n",
        "\n",
        "Let's try to run the following cell to test our model. When prompted for an input, enter any line of text and see what your machine learning model has classified the text as.\n",
        "\n",
        "Try also to load the Naive Bayes model, and load the SVM models and try the text classification for both models.\n",
        "\n",
        "Discuss your findings. \n",
        "\n",
        "1. Which model was more accurate based on the F1-score calculated after training?\n",
        "\n",
        "2. Do you think that the classification has been accurate when you actually tried the model?\n",
        "\n",
        "3. What else can you do to improve the accuracy of the model?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIKDiMip_J0h"
      },
      "outputs": [],
      "source": [
        "print (\"Enter some text:\")\n",
        "user_text = input()\n",
        "classify_text(user_text)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zNlm2Z0nU8od"
      },
      "source": [
        "## Section 1.9 - Explore the helpers.py code\n",
        "\n",
        "Take a look at the code within the helpers.py file to see the codes that load the training and test data, create the Machine Learning model, train the model and perform classification."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "colab-exercise.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}