{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image](https://www.linkpicture.com/q/nyplogo.jpg)\n",
    "\n",
    "\n",
    "Welcome to the lab! Before we get started here are a few pointers on Jupyter notebooks.\n",
    "\n",
    "1. The notebook is composed of cells; cells can contain code which you can run, or they can hold text and/or images which are there for you to read.\n",
    "\n",
    "2. You can execute code cells by clicking the ```Run``` icon in the menu, or via the following keyboard shortcuts ```Shift-Enter``` (run and advance) or \n",
    "```Ctrl-Enter``` (run and stay in the current cell).\n",
    "\n",
    "3. To interrupt cell execution, click the ```Stop``` button on the toolbar or navigate to the ```Kernel``` menu, and select ```Interrupt ```."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p7kdWxWYoOtS"
   },
   "source": [
    "# **Lab 2(solution) Car Object Detection**\n",
    "\n",
    "In this Lab we will try to build a car object detector to helps in the recognition and localization of multiple car instances in an image.\n",
    "\n",
    "The predicted output from the object detector will the label of the object and the bounding box to denote the location of the object. In the following, you can see an example of the object detector predicted 2 objects with label vehicle and 2 bounding boxes to indicate the objects' location.\n",
    "\n",
    "![image](https://www.linkpicture.com/q/object-detection-introduction.png)\n",
    "\n",
    "\n",
    "Similar to the Classification problem, we need to collect the data for training. We will collect images that contain cars and provide labels. For Object Detection problem we also need to annotate the locations of the cars in the images to be part of the label. With the prepared dataset, we can do training with the Object Detection neural network.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "We will build the car object detector based on the following steps\n",
    "\n",
    "1.   Collect images for the class car\n",
    "2.   Annotate each of the objects inside the images \n",
    "3.   Train the model with the training set and evaluate it performance\n",
    "4.   Prediction using trained model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First goto the upper right corner of the jupyter notebook, select the pre-installed python virtual environment.\n",
    "Look for python virtual environment with the name tf1env. Select this for our lab exercise. \n",
    "\n",
    "![image](https://www.linkpicture.com/q/tf1env.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DAdHp9orDa6_"
   },
   "source": [
    "# **1. Collect images for the class car**\n",
    "\n",
    "We have pre-collected about 25 images of the car for this lab.  It is split into 20 images for training and  5 images for validation.\n",
    "\n",
    "It is stored in the following dataset directory.\n",
    "\n",
    "For train data, it is stored in the path ./dataset/Lab2dataset/data/train.\n",
    "```\n",
    "./dataset/Lab2dataset/data/train\n",
    "                           |- annotations\n",
    "                           |- images\n",
    "                   \n",
    "```\n",
    "For train data, it is stored in the path ./dataset/Lab2dataset/data/validation.\n",
    "```\n",
    "./dataset/Lab2dataset/data/validation \n",
    "                           |- annotations\n",
    "                           |- images\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "\n",
    "Try to display different images with the following code.\n",
    "\n",
    "- Set image directory and file name in the imread() function eg.  data_path_train_images+'img1.jpg'\n",
    "\n",
    "If you can do so, that means the dataset is copied correctly into the lab directory.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 23414,
     "status": "ok",
     "timestamp": 1600853236621,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "KhTgJj138RC4",
    "outputId": "69c61f95-5c94-47a6-d9f0-acf69ca4eaf5"
   },
   "outputs": [],
   "source": [
    "#Set the variables to store the different path for dataset\n",
    "data_dir_path='./dataset/Lab2dataset/'\n",
    "models_path='./dataset/Lab2dataset/models/'\n",
    "data_path_train_images='./dataset/Lab2dataset/train/images/'\n",
    "data_path_validation_images='./dataset/Lab2dataset/validation/images/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "# TODO: complete the code below\n",
    "img = mpimg.imread(data_path_train_images+\"img1.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ds3nszHmDtys"
   },
   "source": [
    "# **2. Annotate each of the objects inside the image**\n",
    "\n",
    "In this section we will try to practice how to label and annotate image data. With the help of the LabelImage application, we can label the object and define bounding box parameters.\n",
    "\n",
    "This exercise will be running on the local computer with the Window OS.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to [Annotation exercise](Lab2_Annotation.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tHfoQbCRGjfQ"
   },
   "source": [
    "# **3. Train the model with the training set and evaluate it performance**\n",
    "\n",
    "YOLO(Your Only Look Once) is very popular because it achieves high accuracy while also being able to run in real-time. The algorithm “only looks once” at the image in the sense that it only requires the image or the video to pass through the neural network once to make predictions.\n",
    "\n",
    "With YOLO, a single CNN simultaneously predicts multiple bounding boxes and class probabilities for those boxes. This means they recognize where the object is at and uses bounding boxes to show where it is at, and uses class probability to determine what the object is.\n",
    "\n",
    "\n",
    "![image](https://www.linkpicture.com/q/yolo_1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fks1o7zc83IX"
   },
   "source": [
    "### Exercise\n",
    "\n",
    "In this exercise we are going to define the Custom YOLO Object Detection model and perform training.\n",
    "\n",
    "We will reuse a YOLO pre-trained model in our problem, this is also known as transfer learning. Transfer learning exploits the knowledge gained from a previous task to improve generalization about another. \n",
    "\n",
    "Complete the following steps to add the codes.\n",
    "\n",
    "- Set the image dataset directory for the training. Remember we have copy our dataset to the directory /dataset/Lab2dataset/data/train previously. Define the directory inside the function trainer.setDataDirectory(data_directory= directory)\n",
    "\n",
    "   \n",
    "- Set our YOLO object detection model training parameters in the following function \n",
    "```\n",
    "trainer.setTrainConfig()\n",
    "```\n",
    "\n",
    "    *   object_names_array : this is an array containing the names of the objects in our dataset(in our case we labeled it car) eg. ['car']\n",
    "    *   batch_size : The batch size allow large dataset to be able to load into the model for training\n",
    "    *   num_experiments : The number of times the network will train over all the training images, which is also called epochs\n",
    "    *   train_from_pretrained_model : pre-trained YOLOv3 model file name\n",
    "\n",
    "\n",
    "\n",
    "- Set the num_experiements=5 and run the training. Use the Jupyter file browser, goto directory './dataset/Lab2dataset/models/'. How many weigths files are stored in the directory? How do you know which weight is the best trianed model?\n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "There are 5 files beacause we setted the iterations to be 5.\n",
    "The file name is form using iteration number and the loss value.\n",
    " eg. detection_model-ex-025--loss-0005.643.h5\n",
    " From the smallest loss value of the file name we can determine which is the best weights.  \n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "\n",
    "You can use these different trained weights to test the prediction in the next exercise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "FrVHH-Ha9CVl",
    "outputId": "11ce3c80-fc36-4cec-d503-d0b51a9543d0"
   },
   "outputs": [],
   "source": [
    "\n",
    "from imageai.Detection.Custom import DetectionModelTrainer\n",
    "trainer = DetectionModelTrainer()\n",
    "trainer.setModelTypeAsYOLOv3()\n",
    "\n",
    "# TODO: complete the code below-add the main path where data is stored\n",
    "trainer.setDataDirectory(data_directory=  data_dir_path)\n",
    "                         \n",
    "# TODO: complete the code below-Set the training parameters \n",
    "trainer.setTrainConfig(object_names_array=['car'], num_experiments=5,batch_size=4, train_from_pretrained_model=data_dir_path+\"pretrained-yolov3.h5\")\n",
    "\n",
    "trainer.trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iX-LsyOFHnup"
   },
   "source": [
    "# 4. Prediction using trained model\n",
    "\n",
    "The trained object detection model will predict the objects’ output labels with the corresponding bounding boxes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "For this exercise, we will load the trained weight into the YOLO neural network and perform the prediction.\n",
    "\n",
    "- Choose one of the weights file from the previous exercise. Choose weights with ex-005, assign the directory and file name in the following YOLO neural network function. eg. models_path+'detection_model-ex-005-loss-0016.248.h5'\n",
    "```\n",
    "detector.setModelPath()\n",
    "```\n",
    "- Assign the prediction image directory and file name to the following YOLO neural network function. Give a directory and different file name to store the predicted result. eg. data_dir_path+\"image1.jpg\"\n",
    "```\n",
    "detector.detectObjectsFromImage()\n",
    "```\n",
    "\n",
    "\n",
    "- Run the prediction and observe the output. What do the 3 values represent on each line? \n",
    "<details><summary>Click here for answer</summary> \n",
    "<br/>\n",
    "the 3 values are label name, probability and bounding box. \n",
    "The label name shows the object being classified and the probability displayed how confidence the object being predicted. And the box points show the localization of the object using the bottom left coordinate and the upper right coordinate to form a bounding box.\n",
    "<br/>\n",
    "</details>\n",
    "\n",
    "- Display the image with the predicted result. Add predicted result directory and output image file name to the imread() function(You can find it from the above detector.detectObjectsFromImage() function).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15890,
     "status": "ok",
     "timestamp": 1600854038207,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "jBTP2vr0Hubs",
    "outputId": "c6f5fb01-bdcf-4e07-9ac5-13fbffdb2458"
   },
   "outputs": [],
   "source": [
    "from imageai.Detection.Custom import CustomObjectDetection\n",
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "\n",
    "# TODO: complete the code below\n",
    "detector.setModelPath(models_path+\"detection_model-ex-005--loss-0021.841.h5\")\n",
    "\n",
    "detector.setJsonPath(data_dir_path+\"json/detection_config.json\")\n",
    "\n",
    "detector.loadModel()\n",
    "\n",
    "# TODO: complete the code below\n",
    "detections = detector.detectObjectsFromImage(input_image=data_dir_path+\"image1.jpg\", output_image_path=data_dir_path+\"image1out.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "\n",
    "img = mpimg.imread(data_dir_path+\"image1out.jpg\")\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have loaded the weights into the YOLO model, you can continue to use it to predict other images.\n",
    "\n",
    "- Assign another prediction image directory and file name to the following YOLO neural network function. Give a directory and different file name to store the predicted result.eg. data_dir_path+\"image2.jpg\"\n",
    "\n",
    "- Display the image with the predicted result. Add directory and output image file name from prediction to the imread() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 33
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3076,
     "status": "ok",
     "timestamp": 1600854071904,
     "user": {
      "displayName": "NYP weech",
      "photoUrl": "",
      "userId": "03211871160483530494"
     },
     "user_tz": -480
    },
    "id": "PKPKBwYyEpuS",
    "outputId": "7f4e2f6b-96c2-4375-a6f1-d51b61d23fe2"
   },
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=data_dir_path+\"image6.jpg\", output_image_path=data_dir_path+\"image6out.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "\n",
    "img = mpimg.imread(data_dir_path+\"image6out.jpg\")\n",
    "plt.imshow(img)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with the given pre-trained weights(trained_detection_model-ex-025--loss-0005.643.h5) with lower loss value compare with the previous step. \n",
    "Compare the probability and the postion of the bounding box with the ones predicted by the model using epoch 3 weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = CustomObjectDetection()\n",
    "detector.setModelTypeAsYOLOv3()\n",
    "\n",
    "# TODO: complete the code below\n",
    "detector.setModelPath(models_path+\"trained_detection_model-ex-025--loss-0005.643.h5\")\n",
    "\n",
    "detector.setJsonPath(data_dir_path+\"json/detection_config.json\")\n",
    "\n",
    "detector.loadModel()\n",
    "\n",
    "# TODO: complete the code below\n",
    "detections = detector.detectObjectsFromImage(input_image=data_dir_path+\"image1.jpg\", output_image_path=data_dir_path+\"image1out.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "\n",
    "img = mpimg.imread(data_dir_path+\"image1out.jpg\")\n",
    "plt.imshow(img)\n",
    "                                             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detector.detectObjectsFromImage(input_image=data_dir_path+\"image3.jpg\", output_image_path=data_dir_path+\"image3out.jpg\")\n",
    "for detection in detections:\n",
    "    print(detection[\"name\"], \" : \", detection[\"percentage_probability\"], \" : \", detection[\"box_points\"])\n",
    "\n",
    "img = mpimg.imread(data_dir_path+\"image3out.jpg\")\n",
    "plt.imshow(img)\n",
    "                   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyM+0kFKqv5vdeYNERkCEuvP",
   "name": "Lab3_Car_ObjectDetection.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
